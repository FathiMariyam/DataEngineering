{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uber pickups â€” quick exploratory analysis\n",
        "\n",
        "This notebook loads a public Uber pickups CSV (April 2014) and shows a short EDA: head, basic stats, pickups by hour, and a simple map scatter (if running locally with matplotlib). Designed to be runnable immediately in Colab / local Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install any missing packages (uncomment if needed)\n",
        "# !pip install -q pandas matplotlib seaborn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Public CSV (April 2014) from a public repo\n",
        "url = 'https://raw.githubusercontent.com/fivethirtyeight/uber-tlc-foil-response/master/uber-trip-data/uber-raw-data-apr14.csv'\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv(url)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "display(df.head())\n",
        "print('\\nRows, cols:', df.shape)\n",
        "\n",
        "# Parse datetime column (column is named 'Date/Time' in that CSV)\n",
        "if 'Date/Time' in df.columns:\n",
        "    df['Date/Time'] = pd.to_datetime(df['Date/Time'])\n",
        "    df['hour'] = df['Date/Time'].dt.hour\n",
        "    df['date'] = df['Date/Time'].dt.date\n",
        "else:\n",
        "    print('Expected column \"Date/Time\" not found; available columns:', df.columns.tolist())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick aggregated plots\n",
        "plt.figure(figsize=(10,4))\n",
        "if 'hour' in df.columns:\n",
        "    hourly = df.groupby('hour').size()\n",
        "    sns.barplot(x=hourly.index, y=hourly.values, palette='viridis')\n",
        "    plt.xlabel('Hour of day')\n",
        "    plt.ylabel('Number of pickups')\n",
        "    plt.title('Uber pickups by hour (Apr 2014)')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No hour column', ha='center')\n",
        "plt.show()\n",
        "\n",
        "# Top 5 dates\n",
        "if 'date' in df.columns:\n",
        "    top_dates = df['date'].value_counts().head(10)\n",
        "    print('\\nTop pickup dates (count):')\n",
        "    print(top_dates)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simple scatter of lat/lon (may be dense); zoom with alpha\n",
        "if {'Lat','Lon'}.issubset(set(df.columns)):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(df['Lon'], df['Lat'], s=1, alpha=0.3)\n",
        "    plt.title('Pickup locations (Lon/Lat)')\n",
        "    plt.xlabel('Longitude')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.show()\n",
        "else:\n",
        "    print('No Lat/Lon columns available for map scatter.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps / reproducibility\n",
        "\n",
        "1. If you want this notebook placed into your public repo `DataEngineering`, either push it yourself (instructions below) or give me permission and I will push it.\n",
        "2. If the original ShivramSriramulu/Uber-analysis repo contains different or additional data, upload those CSVs into the repo and adjust the `url` or path in the first code cell.\n",
        "\n",
        "### Quick commands to run notebook locally or in Colab:\n",
        "- Upload this notebook to Colab (File -> Upload notebook) and run, or run locally with: jupyter notebook\n"
      ]
    }
  ]
}
